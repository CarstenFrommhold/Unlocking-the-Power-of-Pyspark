{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2526181-199f-464f-9729-3db261bc041b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cloud Motivation\n",
    "\n",
    "Let's take a quick look at the case we're about to simulate in the cloud. We already know the data that we see now. In reality, however, we do not know the target variable, of course. \n",
    "\n",
    "Let's say the target variable specifies a churn probability. Depending on the churn probability of a model, an incentive is to be stored for each customer.\n",
    "\n",
    "For this we will:\n",
    "* Read three data sources.\n",
    "* Join them.\n",
    "* Encode the categorical variable *region*\n",
    "* Load and apply the model\n",
    "* Apply the business logic based on the prediction of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40359b-9faa-458b-875d-b51b2dcc78ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Utils & Local Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333f85f-585b-4649-9e39-efec2cb277da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.base import Transformer\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "\n",
    "FEATURES = ['n1', 'n2', 'n3', 'n4_1', 'n4_2', 'n4_3']\n",
    "TARGET = 'target'\n",
    "\n",
    "\n",
    "def merge_dataframes(df_customer_usage: DataFrame,\n",
    "                     df_customer_master: DataFrame,\n",
    "                     df_demographics: DataFrame) -> DataFrame:\n",
    "    \"\"\" Merge dataframes \"\"\"\n",
    "    df = df_customer_master.join(df_customer_usage, on=\"customer_id\")\n",
    "    df = df.join(df_demographics, on=\"postal_code\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_encode_region(df: DataFrame) -> DataFrame:\n",
    "    \"\"\" One hot encode region \"\"\"\n",
    "    df = df.withColumn(\"n4_1\", F.when(F.col(\"region\") == F.lit(\"City\"), 1).otherwise(0))\n",
    "    df = df.withColumn(\"n4_2\", F.when(F.col(\"region\") == F.lit(\"Country\"), 1).otherwise(0))\n",
    "    df = df.withColumn(\"n4_3\", F.when(F.col(\"region\") == F.lit(\"Intermediate Area\"), 1).otherwise(0))\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_data(df_customer_usage: DataFrame,\n",
    "                    df_customer_master: DataFrame,\n",
    "                    df_demographics: DataFrame) -> DataFrame:\n",
    "    \"\"\" Preprocess data \"\"\"\n",
    "    df = merge_dataframes(df_customer_usage, df_customer_master, df_demographics)\n",
    "    df = one_hot_encode_region(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_random_forest_classifier(df: DataFrame) -> Transformer:\n",
    "    \"\"\" Train random forest classifier \"\"\"\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=FEATURES, outputCol='features')\n",
    "    train_data = assembler.transform(df).select('features', TARGET)\n",
    "\n",
    "    clf = RandomForestClassifier(featuresCol='features', labelCol=TARGET, numTrees=100, maxDepth=2, seed=42)\n",
    "    model = clf.fit(train_data)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def apply_proba(clf: Transformer, df: DataFrame) -> DataFrame:\n",
    "    \"\"\" Apply probability \n",
    "    Note that the transformer predicts the probability for each class, resulting in a vector of length 2.\n",
    "    This vector is of type VectorUDT, which is not supported by Spark SQL.\n",
    "    Therefore, we need to convert it to an array of doubles.\n",
    "    \"\"\"\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=FEATURES, outputCol='features')\n",
    "    df = assembler.transform(df)\n",
    "    df = clf.transform(df)\n",
    "\n",
    "    df = df.withColumn(\"probability_vec\", vector_to_array(F.col(\"probability\")))\n",
    "    df = df.withColumn(\"proba\", F.element_at(F.col(\"probability_vec\"), 2))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c66702-eb1b-463e-9403-4276c245f809",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark_session = SparkSession.builder.appName(\"BusinessCase\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06f8eb-aa98-43fd-adc5-8db77df1f63e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark_session.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6500d-5aab-4f99-8797-3645ab7b5507",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739a267-a5b1-4eb6-8a3c-2ee76fedfb5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_customer_master = spark_session.read.parquet(\"data/customer_master_data_wo_target\")\n",
    "df_customer_usage = spark_session.read.parquet(\"data/customer_usage_data\")\n",
    "df_demographics = spark_session.read.parquet(\"data/demographics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba7bc9-c74e-4788-a1de-5ae065f8bb6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_customer_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb39a40-8e90-47b3-b9f6-533cbebc0eac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_customer_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b1cc7-7a31-42ed-9ca5-775d2b9e052f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11312799-38f8-4c18-b588-1903498dcefb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Preprocess\n",
    "\n",
    "* Join\n",
    "* One Hot Encode *region*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873432b-6049-4d82-a66a-a224d53e22db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = preprocess_data(df_customer_usage, df_customer_master, df_demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4d00a-9952-4c9e-89a0-2c2de9758be2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09496b-ab55-45ae-a22c-0a8c14b58988",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Apply Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e874fe6-d4dc-4428-8c07-b7e85f22c26d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassificationModel.load(\"data/rf_classifier_model\")\n",
    "df = apply_proba(model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82b2bd-4e00-4066-80fb-777ccf8fcddf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94950e52-8bc0-4ef8-ad8c-85527734804c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Business Layer\n",
    "\n",
    "* Apply a business logic, based on the propabiliites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343247c7-1b20-45e8-8241-60e388b226be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_business_logic(df: DataFrame) -> DataFrame:\n",
    "    \"\"\" Apply business logic \"\"\"\n",
    "    df = df.withColumn(\"incentive\", F.lit(\"fallback\"))\n",
    "    df = df.withColumn(\"incentive\", F.when(F.col(\"proba\") >= F.lit(0.1), \"v01\").otherwise(F.col(\"incentive\")))\n",
    "    df = df.withColumn(\"incentive\", F.when(F.col(\"proba\") >= F.lit(0.2), \"v02\").otherwise(F.col(\"incentive\")))\n",
    "    df = df.withColumn(\"incentive\", F.when(F.col(\"proba\") >= F.lit(0.3), \"v03\").otherwise(F.col(\"incentive\")))\n",
    "    df = df.withColumn(\"incentive\", F.when(F.col(\"proba\") >= F.lit(0.4), \"v04\").otherwise(F.col(\"incentive\")))\n",
    "    df = df.withColumn(\"incentive\", F.when(F.col(\"proba\") >= F.lit(0.5), \"v05\").otherwise(F.col(\"incentive\")))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd33d75-1ec7-4ce0-a82d-2a00a73e9948",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = apply_business_logic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8729bf37-f1bd-4ca8-90ab-cf86a12164dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6299a88a-6de4-4618-84c4-e842aba2ec8d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Let's move to cloud.\n",
    "\n",
    "So let's do this, but on a real cluster.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/s3_glue.drawio.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b93fab-377b-4073-b3e7-6aba59236894",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa07bd-b5ac-44f4-adb0-146b382b13d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
